<docs lang="markdown">
Describe your plugin here.
</docs>

<config lang="json">
{
  "name": "PythonServer",
  "type": "native-python",
  "version": "0.1.0",
  "api_version": "0.1.2",
  "description": "[TODO: describe this plugin with one sentence.]",
  "tags": [],
  "ui": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "env": "",
  "requirements": [],
  "runnable": false,
  "dependencies": ["supermanhuyu/ImJoy-Demo-Plugins:ResultWindow",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20I.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20II.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20III.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20IV.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20V.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20VI.imjoy.html"]
}
</config>

<script lang="python">
import os
import time
import random
import numpy as np
import tensorflow as tf
from keras.models import load_model
from multiprocessing import Queue, Pool, Process
import h5py
os.chdir("./faceid")
import facenet
import detect_face
from timer import Timer
from face import single_detection, single_compare, single_recognition, baseid_import, alive_detection
model_file = "models/models.pb"
emb_h5 = "models/embeddings.h5"
face_vgg = "models/face_vgg16.h5"
http_server = "https://facefiles.sg-ai.com/"
# http_server = "http://192.168.199.107:8000/"

class ImJoyPlugin():
    def setup(self):
        print('setup in python')
        self.class_name = None
        self.emb_arr = None
        self.pretrain_init()
        print('pretrain_init finished.')

    def run(self):
        print('starting server ... ')

    # 人脸模型预加载
    def pretrain_init(self):
        with tf.Graph().as_default():
            # Load the model
            facenet.load_model(model_file)
            # Get input and output tensors
            self.images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
            self.embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
            self.phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
            sess = tf.Session()
            self.sess = sess
            with sess.as_default():
                self.pnet, self.rnet, self.onet = detect_face.create_mtcnn(sess, None)
            return True

    # 人脸检测
    async def predict(self, list):
    # def predict(self, list):
        res = []
        for item in list:
            # print(item)
            # result_file = facefile_detection(item["filename"], item["path"])
            result_file = single_detection(item["filename"], item["path"], self.pnet, self.rnet, self.onet)
            if result_file:
                res.append({'IOU': random.uniform(0.91, 1), 'fileName': item["filename"], 'url1': http_server + result_file,
                            'message': ''})
            else:
                res.append({'IOU': random.uniform(0.91, 1), 'fileName': item["filename"], 'url1': item["url"],
                            'message': '不存在人脸'})

        print(res)
        return res

    # 1:1 人脸核验
    async def predictII(self, args):
    # def predictII_(self, args):
        print(args)
        input_dir = args[0]["path"]
        detect_timer = Timer()
        with tf.Graph().as_default():
            # Load the model
            facenet.load_model(model_file)
            # Get input and output tensors
            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")

            sess = tf.Session()
            with sess.as_default():
                pnet, rnet, onet = detect_face.create_mtcnn(sess, None)
            compare_dirs = os.listdir(input_dir)

            win = await api.createWindow({
                'name': 'ResultWindow',
                'type': 'ResultWindow',
                'w': 10, 'h': 10,
                'data': {'ID': 0, 'flag': '是', 'time': '0s'}})
            wait = None
            for compare_dir in compare_dirs:
                image_files = os.listdir(os.path.join(input_dir, compare_dir))
                detect_timer.tic()
                dist = single_compare(input_dir, compare_dir, image_files,
                               pnet, rnet, onet, images_placeholder, embeddings, phase_train_placeholder, sess)

                detect_timer.toc()

                if dist < 0.85:
                    flag = "是"
                else:
                    flag = "否"
                print('ID:', compare_dir, "dist:", dist, "flag:", flag, "time:", detect_timer.diff)
                if wait is not None:
                    await wait
                wait = win.run({
                        'function': 'FunctionII',
                        'data': {'ID': compare_dir, 'flag': flag, 'time': detect_timer.diff,
                                 'url1': http_server + os.path.join(input_dir, compare_dir, image_files[0]),
                                 'url2': http_server + os.path.join(input_dir, compare_dir, image_files[1])}})
        return True

    # 1:1 人脸核验
    async def predictII(self, args):
    # def predictII(self, args):
        print(args)
        input_dir = args[0]["path"]
        detect_timer = Timer()
        compare_dirs = os.listdir(input_dir)

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 10, 'h': 10,
            'data': {'ID': 0, 'flag': '是', 'time': '0s'}})
        wait = None
        for compare_dir in compare_dirs:
            image_files = os.listdir(os.path.join(input_dir, compare_dir))
            detect_timer.tic()
            dist = single_compare(input_dir, compare_dir, image_files,
                                  self.pnet, self.rnet, self.onet,
                                  self.images_placeholder, self.embeddings, self.phase_train_placeholder, self.sess)

            detect_timer.toc()

            if dist < 0.85:
                flag = "是"
            else:
                flag = "否"
            print('ID:', compare_dir, "dist:", dist, "flag:", flag, "time:", detect_timer.diff)
            if wait is not None:
                await wait
            wait = win.run({
                    'function': 'FunctionII',
                    'data': {'ID': compare_dir, 'flag': flag, 'time': detect_timer.diff,
                             'url1': http_server + os.path.join(input_dir, compare_dir, image_files[0]),
                             'url2': http_server + os.path.join(input_dir, compare_dir, image_files[1])}})
        return True

    # 1:n人脸识别 导入底库
    async def importBaseid(self, args):
    # def importBaseid(self, args):
        print('data path:', args[0]["path"])
        if baseid_import(args[0]["path"]):
            f = h5py.File(emb_h5, 'r')
            class_arr = f['class_name'][:]
            self.class_name = [k.decode() for k in class_arr]
            self.emb_arr = f['embeddings'][:]
            f.close()
            return True
        else:
            return False

    # 1:n人脸识别 预测
    async def predictIII(self, args):
    # def predictIII_(self, args):
        print(args)
        input_dir = args[0]["path"]
        image_files = os.listdir(input_dir)
        output_dir = "data/result/"
        detect_timer = Timer()

        # f = h5py.File(emb_h5, 'r')
        # class_arr = f['class_name'][:]
        # class_name = [k.decode() for k in class_arr]
        # emb_arr = f['embeddings'][:]
        # f.close()
        if self.class_name is not None:
            class_name = self.class_name
            emb_arr = self.emb_arr
        else:
            f = h5py.File(emb_h5, 'r')
            class_arr = f['class_name'][:]
            class_name = [k.decode() for k in class_arr]
            emb_arr = f['embeddings'][:]
            f.close()

        # print("class_name: ", class_name)

        with tf.Graph().as_default():
            # Load the model
            facenet.load_model(model_file)
            # Get input and output tensors
            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")

            sess = tf.Session()
            with sess.as_default():
                pnet, rnet, onet = detect_face.create_mtcnn(sess, None)

            win = await api.createWindow({
                'name': 'ResultWindow',
                'type': 'ResultWindow',
                'w': 10, 'h': 10,
                'data': {'fileName': '', 'flag': '是', 'time': '0s', 'message': ''}
            })
            wait = None

            for img in image_files:
                detect_timer.tic()
                save_img, img_id = single_recognition(input_dir, img, output_dir, emb_arr, class_name,
                                                      pnet, rnet, onet,
                                                      images_placeholder, embeddings, phase_train_placeholder, sess)
                detect_timer.toc()
                flag = "是"
                message = ""
                if save_img == "none":
                    flag = "否"
                    message = "没有人脸"
                elif img_id == "none":
                    flag = "否"
                data_dict = {'fileName': img,
                             'flag': flag,
                             'time': detect_timer.diff,
                             'id': img_id,
                             'url1': http_server+save_img,
                             'message': message}
                print(data_dict)
                if wait is not None:
                    await wait
                wait = win.run({'function': 'FunctionIII', 'data': data_dict})
        return '1'

    # 1:n人脸识别 预测
    async def predictIII(self, args):
    # def predictIII(self, args):
        print(args)
        input_dir = args[0]["path"]
        image_files = os.listdir(input_dir)
        output_dir = "data/result/"
        detect_timer = Timer()

        f = h5py.File(emb_h5, 'r')
        class_arr = f['class_name'][:]
        class_name = [k.decode() for k in class_arr]
        emb_arr = f['embeddings'][:]
        f.close()
        # if self.class_name is not None:
        #     class_name = self.class_name
        #     emb_arr = self.emb_arr
        # else:
        #     print("prepare to import embeddings to memery ...")
        #     f = h5py.File(emb_h5, 'r')
        #     class_arr = f['class_name'][:]
        #     class_name = [k.decode() for k in class_arr]
        #     emb_arr = f['embeddings'][:]
        #     f.close()

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 10, 'h': 10,
            'data': {'fileName': '', 'flag': '是', 'time': '0s', 'message': ''}
        })
        wait = None

        for img in image_files:
            detect_timer.tic()
            save_img, img_id = single_recognition(input_dir, img, output_dir, emb_arr, class_name,
                                                  self.pnet, self.rnet, self.onet,
                                                  self.images_placeholder, self.embeddings, self.phase_train_placeholder, self.sess)
            detect_timer.toc()
            flag = "是"
            message = ""
            if save_img == "none":
                flag = "否"
                message = "没有人脸"
            elif img_id == "none":
                flag = "否"
            data_dict = {'fileName': img,
                         'flag': flag,
                         'time': detect_timer.diff,
                         'id': img_id,
                         'url1': http_server+save_img,
                         'message': message}
            print(data_dict)
            if wait is not None:
                await wait
            wait = win.run({'function': 'FunctionIII', 'data': data_dict})
        return '1'

    # 关键点检测
    async def predictIV(self, args):
    # def predictIV(self, args):
        print(args)

        # win = await api.createWindow({
        #     'name': 'ResultWindow',
        #     'type': 'ResultWindow',
        #     'w': 10, 'h': 10,
        #     'data': {'fileName': '', 'keyPoint': ''}
        # })

        # win.run({'function': 'FunctionIV',
        #          'data': {'fileName': 'cat.jpg', 'keyPoint': '[{x: 1, y: 1}, {x2: 2, y2: 2}]'}})
        return '1'

    # 活体检测
    async def predictV(self, args):
    # def predictV(self, args):
        print(args)
        input_dir = args[0]["path"]
        model = load_model(face_vgg)
        image_files = os.listdir(input_dir)
        image_files.sort()

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 10, 'h': 10,
            'data': {'fileName': '', 'flag': ''}
        })
        wait = None
        for img in image_files:
            flag = alive_detection(os.path.join(input_dir, img), model)

            data_dict = {'fileName': img, 'flag': flag}
            print(data_dict)
            if wait is not None:
                await wait
            wait = win.run({'function': 'FunctionIII', 'data': data_dict})
        return '1'

    # 图像质量检测
    async def predictVI(self, args):
        print(args)
        # win = await api.createWindow({
        #     'name': 'ResultWindow',
        #     'type': 'ResultWindow',
        #     'w': 10, 'h': 10,
        #     'data': {'fileName': '', 'message': ''}
        # })
        # i = 1
        # while i <= 25:
        #     win.run({'function': 'FunctionVI', 'data': {'fileName': 'cat.jpg', 'message': '图像模糊,详细描述...'}})
        #     i += 1
        return '1'


    def exit(self):
        print('aborting servers...')


api.export(ImJoyPlugin())
</script>
